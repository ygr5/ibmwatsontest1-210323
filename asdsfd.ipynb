{
    "cells": [
        {
            "metadata": {
                "collapsed": true
            },
            "cell_type": "markdown",
            "source": "# sdsfgd\nhhhhh"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "// @hidden_cell\nimport com.ibm.ibmos2spark.CloudObjectStorage\nvar configurationName = \"os_73cfa99d8161482187b82d2a3a781aef_configs\"\n\nif (System.getenv(\"RUNTIME_ENV_LOCATION_TYPE\") == \"external\") {\n    endpoint_73cfa99d8161482187b82d2a3a781aef = \"https://s3-api.us-geo.objectstorage.softlayer.net\"\n} else {\n    endpoint_73cfa99d8161482187b82d2a3a781aef = \"https://s3-api.us-geo.objectstorage.service.networklayer.com\"\n}\n\ndef getCredentials(): scala.collection.mutable.HashMap[String, String] = {\n    return scala.collection.mutable.HashMap[String, String] (\n    \"endPoint\"-> endpoint_73cfa99d8161482187b82d2a3a781aef,\n    \"apiKey\"->\"Uwhl8ymMlU3iffS74Um8I_ar_VvBkGFkWF7vgvm8k8X6\",\n    \"serviceId\"->\"iam-ServiceId-2a98d6e0-7744-4d94-a2ab-12001d05d9ed\",\n    \"iamServiceEndpoint\" -> \"https://iam.cloud.ibm.com/oidc/token\")\n}\n\nvar cos = new CloudObjectStorage(sc, getCredentials(), configurationName, \"bluemix_cos\")\n\nimport org.apache.spark.sql.SparkSession\nval spark = SparkSession.\n    builder().\n    getOrCreate()\nval dfData1 = spark.\n    read.format(\"org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\").\n    option(\"header\", \"true\").\n    option(\"inferSchema\", \"true\").\n    load(cos.url(\"lwtesting1200818-donotdelete-pr-kjzsarxpg8s6wu\", \"sampleunit.csv\"))\ndfData1.show(5)\n",
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "Compile Error",
                    "evalue": "<console>:34: error: not found: value endpoint_73cfa99d8161482187b82d2a3a781aef\n           endpoint_73cfa99d8161482187b82d2a3a781aef = \"https://s3-api.us-geo.objectstorage.softlayer.net\"\n           ^\n<console>:36: error: not found: value endpoint_73cfa99d8161482187b82d2a3a781aef\n           endpoint_73cfa99d8161482187b82d2a3a781aef = \"https://s3-api.us-geo.objectstorage.service.networklayer.com\"\n           ^\n<console>:41: error: not found: value endpoint_73cfa99d8161482187b82d2a3a781aef\n           \"endPoint\"-> endpoint_73cfa99d8161482187b82d2a3a781aef,\n                        ^\n",
                    "traceback": []
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\nval dfData2 = spark.\n    read.format(\"org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\").\n    option(\"header\", \"true\").\n    option(\"inferSchema\", \"true\").\n    load(cos.url(\"lwtesting1200818-donotdelete-pr-kjzsarxpg8s6wu\", \"sampleunit.csv\"))\ndfData2.show(5)\n",
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "Compile Error",
                    "evalue": "<console>:31: error: not found: value cos\n           load(cos.url(\"lwtesting1200818-donotdelete-pr-kjzsarxpg8s6wu\", \"sampleunit.csv\"))\n                ^\n",
                    "traceback": []
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "scala",
            "display_name": "Scala 2.12 with Spark",
            "language": "scala"
        },
        "language_info": {
            "mimetype": "text/x-scala",
            "name": "scala",
            "pygments_lexer": "scala",
            "version": "2.12.12",
            "file_extension": ".scala",
            "codemirror_mode": "text/x-scala"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}